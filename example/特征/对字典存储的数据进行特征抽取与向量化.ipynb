{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义一组字典列表，用来表示多个数据样本(每个字典代表一个数据样本)\n",
    "measurements = [{'city': 'Dubai', 'temperature': 33.},{'city': 'London', 'temperature': 12.}, {'city': 'San Fransisco', 'temperature': 18.}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.   0.   0.  33.]\n",
      " [  0.   1.   0.  12.]\n",
      " [  0.   0.   1.  18.]]\n",
      "['city=Dubai', 'city=London', 'city=San Fransisco', 'temperature']\n"
     ]
    }
   ],
   "source": [
    "# 从 sklearn.feature_extraction 导入 DictVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "# 初始化特征提取器\n",
    "vec = DictVectorizer()\n",
    "# 输出转化之后的特征矩阵\n",
    "print(vec.fit_transform(measurements).toarray())\n",
    "# 输出各个维度的特征含义\n",
    "print(vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 停用词 -> 最常出现的词 (吃肉，吃菜，吃馒头，吃就是停用词)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 在不去掉停用词的条件下，对文本特征进行量化的朴素贝叶斯分类性能测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 导入20类新闻文本数据抓取器\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "# 下载新闻样本，subset='all' 下载全部并储存在news中\n",
    "news = fetch_20newsgroups(subset = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 分割数据集\n",
    "from sklearn.cross_validation import train_test_split\n",
    "# 对 news 中的数据 data 进行分割，25% 的文本用作测试集，75%作为训练集\n",
    "x_train, x_test, y_train, y_test = train_test_split(news.data, news.target, test_size = 0.25, random_state = 33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# 采用默认的配置进行初始化(默认配置不去除英文停用词)，并赋值个变量 count_vec\n",
    "count_vec = CountVectorizer()\n",
    "# 只使用词频统计的方式将原始训练和测试文本转化为特征向量\n",
    "x_count_train = count_vec.fit_transform(x_train)\n",
    "x_count_test = count_vec.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入 朴素贝叶斯分类器\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# 使用默认的配置对分类器进行初始化\n",
    "mnb_count = MultinomialNB()\n",
    "# 使用朴素贝叶斯分类器，对 CountVectorizer(不去除停用词)后的训练样本进行参数学习\n",
    "mnb_count.fit(x_count_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.839770797963\n"
     ]
    }
   ],
   "source": [
    "# 模型准确性结果\n",
    "print(mnb_count.score(x_count_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 将分类预测的结果储存在变量 y_count_predict 中\n",
    "y_count_predict = mnb_count.predict(x_count_test)\n",
    "# 导入 classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "# 输出详细的其他评价分类性能的指标\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
